{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The purpose of this notebook will be to better understand the seasonality, trend, and business cycles\n",
    "affecting prices on new and incoming contracts.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function statsmodels.tsa.seasonal.seasonal_decompose>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def date_to_datetime(time_string):\n",
    "    return datetime.datetime.strptime(time_string, '%m/%d/%Y')\n",
    "\n",
    "def money_to_float(string):\n",
    "    \"\"\"\n",
    "    hourly wages have dollar signs and use commas, \n",
    "    this method removes those things, so we can treat stuff as floats\n",
    "    \"\"\"\n",
    "    if type(string) == type(str()):\n",
    "        string = string.replace(\"$\",\"\").replace(\",\",\"\")\n",
    "        return float(string)\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "#checking for seasonality: \n",
    "#http://stackoverflow.com/questions/34457281/decomposing-trend-seasonal-and-residual-time-series-elements\n",
    "\n",
    "sm.tsa.seasonal_decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import qqplot\n",
    "from scipy.optimize import brute\n",
    "import statistics\n",
    "from functools import partial\n",
    "\n",
    "\"\"\"\n",
    "A bit about this file - Python is a great language full of lots of useful data science libraries.  But it's not that fast.  For this reason we use a series of functions which send data to json files, which can be used by the language as Python Dictionaries.  Because of the size of the data, big but not *that* big, it made sense to chop up the tasks and not repeat computation unless necessary.  Otherwise debugging and iteration would be difficult, because just processing the data, takes a while.\n",
    "\n",
    "Therefore we have the following methods:\n",
    "\n",
    "making_categories - which maps individual labor categories into buckets across three fields - education level, years of experience and schedule.\n",
    "\n",
    "I don't really undetstand what a schedule is, but it's kind of like a geographic region?  As well as a business line / set of skills.  So, if you are a schedule 70, it's likely you're in IT and it's even more likely you're a software developer.  It's worth stating that there is talk of moving over to SIN numbers which are used by the government to do something similar to the schedule, but at a more granular level.  Sometimes these SIN numbers have semantic data attached.  And sometimes, they do not.  So it's best to think of them as unique identifiers.  For this reason, it might be worth it to update this script down the road to work off of SIN numbers.  But for right now schedule seems like the right call.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#helpful resource: https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
    "\n",
    "def is_nan(obj):\n",
    "    if type(obj) == type(float()):\n",
    "        return math.isnan(obj)\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def money_to_float(string):\n",
    "    \"\"\"\n",
    "    hourly wages have dollar signs and use commas, \n",
    "    this method removes those things, so we can treat stuff as floats\n",
    "    \"\"\"\n",
    "    if type(string) == type(str()):\n",
    "        string = string.replace(\"$\",\"\").replace(\",\",\"\")\n",
    "        return float(string)\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    this loads all the csv's into memory and then returns them.\n",
    "    Note that only versioned csv's are returned, because the one without a version number\n",
    "    is also the highest numbered CSV.  This avoids *some* double counting.\n",
    "    \"\"\"\n",
    "    #loading the datasets into memory\n",
    "    os.chdir(\"data\")\n",
    "    data_sets = [\"hourly_prices_v1.csv\",\"hourly_prices_v2.csv\",\"hourly_prices_v3.csv\",\"hourly_prices_v4.csv\"]\n",
    "    dfs = [pd.read_csv(data_set) for data_set in data_sets]\n",
    "    os.chdir(\"..\")\n",
    "    return dfs\n",
    "\n",
    "def date_to_datetime(time_string):\n",
    "    return datetime.datetime.strptime(time_string, '%m/%d/%Y')\n",
    "\n",
    "def total_error(values,fitted_values):\n",
    "    if (len(values) == len(fitted_values)) or (len(values) < len(fitted_values)):\n",
    "        return sum([abs(values[ind] - fitted_values[ind]) for ind in range(len(values))]) \n",
    "    else:\n",
    "        return sum([abs(values[ind] - fitted_values[ind]) for ind in range(len(fitted_values))])\n",
    "        \n",
    "def check_for_extreme_values(sequence,sequence_to_check=None):\n",
    "    mean = statistics.mean(sequence)\n",
    "    stdev = statistics.stdev(sequence)\n",
    "    if sequence_to_check != None:\n",
    "        for val in sequence_to_check:\n",
    "            if val >= mean + (stdev*2):\n",
    "                sequence_to_check.remove(val)\n",
    "            elif val <= mean - (stdev*2):\n",
    "                sequence_to_check.remove(val)\n",
    "        return sequence_to_check\n",
    "    else:\n",
    "        for val in sequence:\n",
    "            if val >= mean + (stdev*2):\n",
    "                sequence.remove(val)\n",
    "            elif val <= mean - (stdev*2):\n",
    "                sequence.remove(val)\n",
    "        return sequence\n",
    "        \n",
    "def setting_y_axis_intercept(data,model):\n",
    "    data = list(data[\"Year 1/base\"])\n",
    "    fittedvalues = list(model.fittedvalues)\n",
    "    avg = statistics.mean(data)\n",
    "    median = statistics.median(data)\n",
    "    possible_fitted_values = []\n",
    "\n",
    "    possible_fitted_values.append([elem + avg for elem in fittedvalues])\n",
    "    possible_fitted_values.append([elem + data[0] for elem in fittedvalues])\n",
    "    possible_fitted_values.append([elem + median for elem in fittedvalues])\n",
    "    possible_fitted_values.append(fittedvalues)\n",
    "    min_error = 1000000\n",
    "    best_fitted_values = 0\n",
    "    for ind,f_values in enumerate(possible_fitted_values):\n",
    "        cur_error = total_error(data,f_values)\n",
    "        if cur_error < min_error:\n",
    "            min_error = cur_error \n",
    "            best_fitted_values = ind\n",
    "    print(\"minimum error:\",min_error)\n",
    "    return possible_fitted_values[best_fitted_values]\n",
    "\n",
    "def making_categories():\n",
    "    \"\"\"\n",
    "    This function assumes there is a folder called data, that contains csv's with data on schedule information \n",
    "    of different positions to contract for.\n",
    "    this function creates a mapping from labor categories to education level + years of experience + schedule\n",
    "    \"\"\"\n",
    "    \n",
    "    dfs = load_data()\n",
    "    #making use of the mapping of Labor Category to higher level categorization\n",
    "    categories = {\n",
    "        \"None\":{\n",
    "            \"0-5\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"6-10\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"11-15\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            }\n",
    "        },\n",
    "        \"High School\":{\n",
    "            \"0-5\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"6-10\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"11-15\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            }\n",
    "        },\n",
    "        \"Associates\":{\n",
    "            \"0-5\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"6-10\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"11-15\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            }\n",
    "        },\n",
    "        \"Bachelors\":{\n",
    "            \"0-5\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"6-10\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"11-15\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            }\n",
    "        },\n",
    "        \"Masters\":{\n",
    "            \"0-5\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"6-10\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"11-15\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            }\n",
    "        },\n",
    "        \"Ph.D.\":{\n",
    "            \"0-5\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"6-10\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            },\n",
    "            \"11-15\":{\n",
    "                \"PES\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"MOBIS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Environmental\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Logistics\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Consolidated\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"AIMS\":{\"freq\":0,\"labor categories\":[]},\n",
    "                \"Language Services\":{\"freq\":0,\"labor categories\":[]}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    seen_labor_categories = []\n",
    "    years_exp = \"\"\n",
    "    for df in dfs:\n",
    "        for index in df.index:\n",
    "            #this handles double counting, because about 1 out of every 100- every 1000 are double counted\n",
    "            if df.ix[index][\"Labor Category\"] in seen_labor_categories: continue\n",
    "            else:\n",
    "                seen_labor_categories.append(df.ix[index][\"Labor Category\"])\n",
    "            #This part of the code classifies the data into buckets based on some simple rules.\n",
    "            if df.ix[index][\"MinExpAct\"] <6 or is_nan(df.ix[index]):\n",
    "                years_exp = \"0-5\"\n",
    "            elif df.ix[index][\"MinExpAct\"] >=6 and df.ix[index][\"MinExpAct\"] < 11:\n",
    "                years_exp = \"6-10\"\n",
    "            elif df.ix[index][\"MinExpAct\"] >= 11 and df.ix[index][\"MinExpAct\"] < 16:\n",
    "                years_exp = \"11-15\"\n",
    "            \n",
    "            education_level = df.ix[index][\"Education\"] if not is_nan(df.ix[index][\"Education\"]) else \"None\" \n",
    "            categories[ education_level ][ years_exp ][ df.ix[index][\"Schedule\"] ][\"freq\"] += 1\n",
    "            categories[ education_level ][ years_exp ][ df.ix[index][\"Schedule\"] ][\"labor categories\"].append(df.ix[index][\"Labor Category\"])\n",
    "            \n",
    "    json.dump(categories,open(\"categories.json\",\"w\"))\n",
    "\n",
    "def making_labor_category_to_high_level():\n",
    "    \"\"\"\n",
    "    This function assumes making_categories has been called.  \n",
    "    It creates a mapping from individual labor categories to a higher level mapping which will be used in the time series analysis.\n",
    "    Using this function we will create broad labor categories with enough data for a meaningful timeseries\n",
    "    \"\"\"\n",
    "    list_of_categories = []\n",
    "    categories = json.load(open(\"categories.json\",\"r\"))\n",
    "    labor_category_to_high_level_category = {}\n",
    "    for education_level in categories.keys():\n",
    "        for years_of_experience in categories[education_level].keys():\n",
    "            for schedule in categories[education_level][years_of_experience].keys():\n",
    "                for labor_category in categories[education_level][years_of_experience][schedule][\"labor categories\"]:\n",
    "                    labor_category_to_high_level_category[labor_category] = education_level +\"_\"+ years_of_experience +\"_\"+ schedule\n",
    "                    if education_level +\"_\"+ years_of_experience +\"_\"+ schedule not in list_of_categories:\n",
    "                        list_of_categories.append(education_level +\"_\"+ years_of_experience +\"_\"+ schedule)\n",
    "    json.dump(labor_category_to_high_level_category,open(\"labor_category_to_high_level_category.json\",\"w\"))\n",
    "    return list_of_categories\n",
    "\n",
    "#this comes from here: http://stackoverflow.com/questions/22770352/auto-arima-equivalent-for-python\n",
    "def objective_function(data,order):\n",
    "    return sm.tsa.ARIMA(data,order).fit().aic\n",
    "\n",
    "def model_search(data):\n",
    "    obj_func = partial(objective_function,data)\n",
    "    upper_bound_AR = 10\n",
    "    upper_bound_I = 10\n",
    "    upper_bound_MA = 10\n",
    "    grid_not_found = True\n",
    "    while grid_not_found:\n",
    "        try:\n",
    "            if upper_bound_AR < 0 or upper_bound_I < 0 or upper_bound_MA < 0:\n",
    "                grid_not_found = False\n",
    "            grid = (slice(1,upper_bound_AR,1),slice(1,upper_bound_I,1),slice(1,upper_bound_MA,1))\n",
    "            return brute(obj_func, grid, finish=None)\n",
    "        except Exception as e: #found here: http://stackoverflow.com/questions/4308182/getting-the-exception-value-in-python\n",
    "            error_string = str(e)\n",
    "            if \"MA\" in error_string:\n",
    "                upper_bound_MA -= 1\n",
    "            elif \"AR\" in error_string:\n",
    "                upper_bound_AR -= 1\n",
    "            else:\n",
    "                upper_bound_I -= 1\n",
    "                \n",
    "    #assuming we don't ever hit a reasonable set of upper_bounds, it's pretty safe to assume this will work\n",
    "    grid = (slice(1,2,1),slice(1,2,1),slice(1,2,1))\n",
    "    return brute(obj_func, grid, finish=None)\n",
    "                \n",
    "if not os.path.exists(\"categories.json\"):\n",
    "    making_categories()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "dfs = load_data()\n",
    "print(\"loaded_data, took:\",time.time() - start)\n",
    "start = time.time()\n",
    "labor_category = json.load(open(\"labor_category_to_high_level_category.json\",\"r\"))\n",
    "list_of_categories = making_labor_category_to_high_level()\n",
    "set_of_time_series = {}.fromkeys(list_of_categories,pd.DataFrame())\n",
    "print(\"loaded json, ran making_labor_category_to_high_level, took:\",time.time() - start)\n",
    "\n",
    "compressed_dfs = [pd.DataFrame() for _ in range(len(dfs))]\n",
    "start = time.time()\n",
    "for ind,df in enumerate(dfs):\n",
    "    compressed_dfs[ind][\"Year 1/base\"] = df[\"Year 1/base\"]\n",
    "    compressed_dfs[ind][\"Begin Date\"] = df[\"Begin Date\"]\n",
    "    compressed_dfs[ind][\"Labor Category\"] = df[\"Labor Category\"]\n",
    "print(\"compressed dataframes, took\", time.time() - start)\n",
    "\n",
    "#todo: http://pandas.pydata.org/pandas-docs/stable/io.html#hdf5-pytables storing pandas df to disk\n",
    "start = time.time()\n",
    "for df in compressed_dfs:\n",
    "    for ind in df.index:\n",
    "        labor_cat = labor_category[df.ix[ind][\"Labor Category\"]]\n",
    "        set_of_time_series[labor_cat] = set_of_time_series[labor_cat].append(df.ix[ind])\n",
    "print(\"categorizing dataframes, took:\", time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "for category in set_of_time_series.keys():\n",
    "    set_of_time_series[category].index = [date_to_datetime(elem) for elem in set_of_time_series[category][\"Begin Date\"]]\n",
    "    del set_of_time_series[category][\"Begin Date\"]\n",
    "    del set_of_time_series[category][\"Labor Category\"]\n",
    "print(\"organizing categorized dataframes took:\", time.time() - start)\n",
    "\n",
    "print(\"starting model search\")\n",
    "start = time.time()\n",
    "keys = list(set_of_time_series.keys())\n",
    "keys.sort()\n",
    "\n",
    "set_of_time_series = {key:set_of_time_series[key].sort_index(axis=0) for key in keys}\n",
    "models = []\n",
    "\n",
    "#for key in keys:\n",
    "data = set_of_time_series[keys[0]]\n",
    "sm.tsa.seasonal_decompose(data[\"Year 1/base\"])\n",
    "#models.append({\"category\":key,\"model\":model_search(dta)})\n",
    "# model_order = list(model_search(data))\n",
    "# model_order = tuple([int(elem) for elem in model_order])\n",
    "# model = sm.tsa.ARIMA(data,model_order).fit()\n",
    "\n",
    "\n",
    "# model.fittedvalues = setting_y_axis_intercept(data,model)  \n",
    "\n",
    "# plt.plot(data)\n",
    "# plt.plot(model.fittedvalues, color='red')\n",
    "# plt.show()\n",
    "\n",
    "# print(\"finished model search, in:\",time.time() - start)\n",
    "# models = []\n",
    "\n",
    "# keys = list(set_of_time_series.keys())\n",
    "# keys.sort()\n",
    "# dta = set_of_time_series[keys[0]]\n",
    "# dta = dta.sort_index(axis=0)\n",
    "# dta[\"Year 1/base\"] = dta[\"Year 1/base\"].apply(lambda x:math.log(x))\n",
    "\n",
    "# model = sm.tsa.ARIMA(dta,(1,1,0)).fit()\n",
    "# model.fittedvalues = model.fittedvalues.apply(lambda x:x+4)\n",
    "# dicter = {\"category\":keys[0],\"model\":model}\n",
    "# models.append(dicter)\n",
    "\n",
    "# dta = set_of_time_series[keys[1]]\n",
    "# dta = dta.sort_index(axis=0)\n",
    "# model = sm.tsa.ARIMA(dta,(0,1,2)).fit()\n",
    "# model.fittedvalues = model.fittedvalues.apply(lambda x:x+62)\n",
    "# dicter = {\"category\":keys[1],\"model\":model}\n",
    "# models.append(dicter)\n",
    "\n",
    "# dta = set_of_time_series[keys[2]]\n",
    "# dta = dta.sort_index(axis=0)\n",
    "# model = sm.tsa.ARIMA(dta,(0,1,2)).fit()\n",
    "# model.fittedvalues = model.fittedvalues.apply(lambda x:x+50)\n",
    "# dicter = {\"category\":keys[1],\"model\":model}\n",
    "# models.append(dicter)\n",
    "\n",
    "# import IPython\n",
    "# IPython.embed()\n",
    "\n",
    "#serialize model if possible\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
